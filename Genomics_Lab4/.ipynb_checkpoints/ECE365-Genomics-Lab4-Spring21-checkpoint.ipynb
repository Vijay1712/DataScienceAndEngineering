{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: EM Algorithm and Single-Cell RNA-seq Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Your Name Here (Your netid here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due April 2, 2021 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preamble (Don't change this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instructions - \n",
    "\n",
    "1. Please implement all the *graded functions* in main.py file. Do not change function names in main.py.\n",
    "2. Please read the description of every graded function very carefully. The description clearly states what is the expectation of each graded function. \n",
    "3. After some graded functions, there is a cell which you can run and see if the expected output matches the output you are getting. \n",
    "4. The expected output provided is just a way for you to assess the correctness of your code. The code will be tested on several other cases as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = Lab4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Expectation-Maximization (EM) algorithm for transcript quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The EM algorithm is a very helpful tool to compute maximum likelihood estimates of parameters in models that have some latent (hidden) variables.\n",
    "In the case of the transcript quantification problem, the model parameters we want to estimate are the transcript relative abundances $\\rho_1,...,\\rho_K$.\n",
    "The latent variables are the read-to-transcript indicator variables $Z_{ik}$, which indicate whether the $i$th read comes from the $k$th transcript (in which case $Z_{ik}=1$.\n",
    "\n",
    "In this part of the lab, you will be given the read alignment data.\n",
    "For each read and transcript pair, it tells you whether the read can be mapped (i.e., aligned) to that transcript.\n",
    "Using the EM algorithm, you will estimate the relative abundances of the trascripts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading read transcript data - We have 30000 reads and 30 transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reads=30000\n",
    "n_transcripts=30\n",
    "read_mapping=[]\n",
    "with open(\"read_mapping_data.txt\",'r') as file :\n",
    "    lines_reads=file.readlines()\n",
    "for line in lines_reads :\n",
    "    read_mapping.append([int(x) for x in line.split(\",\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 8, 9], [2], [20], [5], [3], [17], [25], [7, 8, 9], [6, 8, 9], [21, 23]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_mapping[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than giving you a giant binary matrix, we encoded the read mapping data in a more concise way. read_mapping is a list of lists. The $i$th list contains the indices of the transcripts that the $i$th read maps to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading true abundances and transcript lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcript_true_abundances.txt\",'r') as file :\n",
    "    lines_gt=file.readlines()\n",
    "ground_truth=[float(x) for x in lines_gt[0].split(\",\")]\n",
    "\n",
    "with open(\"transcript_lengths.txt\",'r') as file :\n",
    "    lines_gt=file.readlines()\n",
    "tr_lengths=[float(x) for x in lines_gt[0].split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0335217035814684,\n",
       " 0.001451311771258088,\n",
       " 0.06523041013235349,\n",
       " 0.005042071648942626,\n",
       " 0.013239743948342543]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4000.0, 4000.0, 3000.0, 3000.0, 1000.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_lengths[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 1 : expectation_maximization (10 marks) \n",
    "\n",
    "Purpose : To implement the EM algorithm to obtain abundance estimates for each transcript.\n",
    "\n",
    "E-step :  In this step, we calculate the fraction of read that is assigned to each transcript (i.e., the estimate of $Z_{ik}$). For read $i$ and transicript $k$, this is calculated by dividing the current abundance estimate of transcript $k$ by the sum of abundance estimates of all transcripts that read $i$ maps to.\n",
    "\n",
    "M-step :  In this step, we update the abundance estimate of each transcript based on the fraction of all reads that is currently assigned to the transcript. First we compute the average fraction of all reads assigned to the transcript. Then, (if transcripts are of different lengths) we divide the result by the transcript length.\n",
    "Finally, we normalize all abundance estimates so that they add up to 1.\n",
    "\n",
    "Inputs - read_mapping (which is a list of lists where each sublist contains the transcripts to which a particular read belongs to. The length of this list is equal to the number of reads, i.e. 30000; tr_lengths (a list containing the length of the 30 transcripts, in order); n_iterations (the number of EM iterations to be performed)\n",
    "\n",
    "Output - a list of lists where each sublist contains the abundance estimates for a transcript across all iterations. The length of each sublist should be equal to the number of iterations plus one (for the initialization) and the total number of sublists should be equal to the number of transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=module.expectation_maximization(read_mapping,tr_lengths,20)\n",
    "print(len(history))\n",
    "print(len(history[0]))\n",
    "print(history[0][-5:])\n",
    "print(history[1][-5:])\n",
    "print(history[2][-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output - \n",
    "\n",
    "30\n",
    "\n",
    "21\n",
    "\n",
    "[0.033769639494636614, 0.03381298624783303, 0.03384568373972948, 0.0338703482393148, 0.03388895326082054]\n",
    "\n",
    "[0.0020082674603036053, 0.0019649207071071456, 0.0019322232152109925, 0.0019075587156241912, 0.0018889536941198502]\n",
    "\n",
    "[0.0660581789629968, 0.06606927656035864, 0.06607650126895578, 0.06608120466668756, 0.0660842666518177]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following function to visualize how the estimated relative abundances are converging with the number of iterations of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_em(history,n_iterations) :\n",
    "    #start code here\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    for j in range(n_transcripts):   \n",
    "        ax.plot([i for i in range(n_iterations+1)],[history[j][i] - ground_truth[j] for i in range(n_iterations+1)],marker='o')\n",
    "    #end code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_em(history,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Exploring Single-Cell RNA-seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a study published in 2015, Zeisel et al. used single-cell RNA-seq data to explore the cell diversity in the mouse brain. \n",
    "We will explore the data used for their study.\n",
    "You can read more about it [here](https://science.sciencemag.org/content/347/6226/1138)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading single-cell RNA-seq data\n",
    "lines_genes=[]\n",
    "with open(\"Zeisel_expr.txt\",'r') as file :\n",
    "    lines_genes=file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_genes[0][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each line in the file Zeisel_expr.txt corresponds to one gene.\n",
    "The columns correspond to different cells (notice that this is the opposite of how we looked at this matrix in class).\n",
    "The entries of this matrix correspond to the number of reads mapping to a given gene in the corresponding cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading true labels for each cell\n",
    "with open(\"Zeisel_labels.txt\",'r') as file :\n",
    "    true_labels = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The study also provides us with true labels for each of the cells.\n",
    "For each of the cells, the vector true_labels contains the name of the cell type.\n",
    "There are nine different cell types in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 2 : prepare_data (10 marks) :\n",
    "\n",
    "Purpose - To create a dataframe where each row corresponds to a specific cell and each column corresponds to the expressions levels of a particular gene across all cells. \n",
    "You should name the columns as \"Gene_1\", \"Gene_2\", and so on.\n",
    "\n",
    "We will iterate through all the lines in lines_genes list created above, add 1 to each value and take log.\n",
    "\n",
    "Each line will correspond to 1 column in the dataframe\n",
    "\n",
    "Output - gene expression dataframe\n",
    "\n",
    "### Note - All the values in the output dataframe should be rounded off to 5 digits after the decimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=module.prepare_data(lines_genes)\n",
    "print(data_df.shape)\n",
    "print(data_df.iloc[0:3,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output :\n",
    "\n",
    "``(3005, 19972)``\n",
    "\n",
    "``   Gene_0    Gene_1    Gene_2   Gene_3    Gene_4``\n",
    "   \n",
    "``0     0.0  1.38629  1.38629     0.0  0.69315``\n",
    "\n",
    "``1     0.0  0.69315  0.69315     0.0  0.69315``\n",
    "\n",
    "``2     0.0  0.00000  1.94591     0.0  0.69315``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 3 : identify_less_expressive_genes (10 marks)\n",
    "\n",
    "Purpose : To identify genes (columns) that are expressed in less than 25 cells. We will create a list of all gene columns that have values greater than 0 for less than 25 cells.\n",
    "\n",
    "Input - gene expression dataframe\n",
    "\n",
    "Output - list of column names which are expressed in less than 25 cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = module.identify_less_expressive_genes(data_df)\n",
    "print(len(drop_columns))\n",
    "print(drop_columns[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output : \n",
    "\n",
    "``5120`` \n",
    "\n",
    "``['Gene_28', 'Gene_126', 'Gene_145', 'Gene_146', 'Gene_151', 'Gene_152', 'Gene_167', 'Gene_168', 'Gene_170', 'Gene_173']``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering less expressive genes\n",
    "\n",
    "We will now create a new dataframe in which genes which are expressed in less than 25 cells will not be present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = data_df.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graded Function 4 :  perform_pca (10 marks)\n",
    "\n",
    "Pupose - Perform Principal Component Analysis on the new dataframe and take the top 50 principal components\n",
    "\n",
    "Input - df_new\n",
    "\n",
    "Output - numpy array containing the top 50 principal components of the data.\n",
    "\n",
    "### Note - All the values in the output should be rounded off to 5 digits after the decimal\n",
    "\n",
    "### Note - Please use random_state=365 for the PCA object you will create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data=module.perform_pca(df_new)\n",
    "print(pca_data.shape)\n",
    "print(type(pca_data))\n",
    "print(pca_data[0:3,:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output : \n",
    "\n",
    "``(3005, 50)``\n",
    "\n",
    "``<class 'numpy.ndarray'>``\n",
    "\n",
    "``[[26.97148  -2.7244  0.62163 25.90148 -6.24736]``\n",
    "\n",
    "`` [26.49135 -1.58774 -4.79315 24.01094 -7.25618]``\n",
    " \n",
    "`` [47.82664  5.06799  2.15177 30.24367 -3.38878]]``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Non-graded) Function 5 :  perform_tsne\n",
    "\n",
    "Pupose - Perform t-SNE on the pca_data and obtain 2 t-SNE components\n",
    "\n",
    "We will use TSNE class of the sklearn.manifold package. Use random_state=1000 and perplexity=50\n",
    "\n",
    "Documenation can be found here - https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n",
    "\n",
    "Input - pca_data\n",
    "\n",
    "Output - numpy array containing the top 2 tsne components of the data.\n",
    "\n",
    "**Note: This function will not be graded because of the random nature of t-SNE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data50 = module.perform_tsne(pca_data)\n",
    "print(tsne_data50.shape)\n",
    "print(tsne_data50[:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Output :\n",
    "\n",
    "(These numbers can deviate a bit depending on your sklearn)\n",
    "\n",
    "``(3005, 2)``\n",
    "\n",
    "``[[ 15.069608 -47.535984]``\n",
    "\n",
    "`` [ 15.251476 -47.172073]``\n",
    " \n",
    "`` [ 13.3932   -49.909657]]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "sns.scatterplot(tsne_data50[:,0], tsne_data50[:,1], hue=true_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the different cell types form clusters (which can be easily visualized on the t-SNE space).\n",
    "Zeisel et al. performed clustering on this data in order to identify and label the different cell types.\n",
    "\n",
    "You can try using clustering methods (such as k-means and GMM) to cluster the single-cell RNA-seq data of Zeisel at al. and see if your results agree with theirs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
